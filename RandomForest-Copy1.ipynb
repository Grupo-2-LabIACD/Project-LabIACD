{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ca2f94-a462-44ba-9905-24efb95d214b",
   "metadata": {},
   "source": [
    "# Random Forest Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805d4d8-4bd6-4a38-b200-e4b5d6fbd9ca",
   "metadata": {},
   "source": [
    "Random Forest Classifier Steps: <br>\n",
    "- Load Main Dataset <br>\n",
    "- Split in Dataset for training and testing <br>\n",
    "- Build Bootstrapped Dataset <br>\n",
    "- Train Decision Trees on those datasets using diferent groups of features<br>\n",
    "- Get Test Data and for each entry on the table make it go through all the trees and take note of the results<br>\n",
    "- Agregate all the results from the different trees and choose the best value thorugh majority voting<br>\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3dcfe7-5271-41cb-8f14-6ab0d2a56e6f",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2286cdaa-f4d2-40fd-828d-8a5433ad8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, explained_variance_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from matplotlib import pyplot \n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "\n",
    "#mainpath=\"C:\\\\Users\\\\alexa\\\\Desktop\\\\github\\\\Project-LabIACD\\\\metadata.csv\"\n",
    "mainpath=\"C:\\\\Users\\\\alexa\\\\Desktop\\\\Tudo\\\\Aulas\\\\LABS\\\\Project-LabIACD\\\\Dataset_clearedv2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf162a7",
   "metadata": {},
   "source": [
    "## Load Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7b0585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_shape_Flatness</th>\n",
       "      <th>original_shape_LeastAxisLength</th>\n",
       "      <th>original_shape_MajorAxisLength</th>\n",
       "      <th>original_shape_Maximum2DDiameterColumn</th>\n",
       "      <th>original_shape_Maximum2DDiameterRow</th>\n",
       "      <th>original_shape_Maximum2DDiameterSlice</th>\n",
       "      <th>original_shape_Maximum3DDiameter</th>\n",
       "      <th>original_shape_MeshVolume</th>\n",
       "      <th>original_shape_MinorAxisLength</th>\n",
       "      <th>original_shape_Sphericity</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "      <th>original_ngtdm_Busyness</th>\n",
       "      <th>original_ngtdm_Coarseness</th>\n",
       "      <th>original_ngtdm_Complexity</th>\n",
       "      <th>original_ngtdm_Contrast</th>\n",
       "      <th>original_ngtdm_Strength</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>SurfaceArea</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Malignancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>0.375133</td>\n",
       "      <td>4.534490</td>\n",
       "      <td>12.087678</td>\n",
       "      <td>12.806248</td>\n",
       "      <td>11.401754</td>\n",
       "      <td>13.928388</td>\n",
       "      <td>14.628739</td>\n",
       "      <td>313.083333</td>\n",
       "      <td>9.595771</td>\n",
       "      <td>0.664923</td>\n",
       "      <td>...</td>\n",
       "      <td>5.572814</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.026869</td>\n",
       "      <td>692.801198</td>\n",
       "      <td>0.218292</td>\n",
       "      <td>7.349337</td>\n",
       "      <td>9.827235</td>\n",
       "      <td>254.249082</td>\n",
       "      <td>140.178680</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>0.687954</td>\n",
       "      <td>8.589183</td>\n",
       "      <td>12.485120</td>\n",
       "      <td>14.422205</td>\n",
       "      <td>14.317821</td>\n",
       "      <td>12.649111</td>\n",
       "      <td>15.165751</td>\n",
       "      <td>605.541667</td>\n",
       "      <td>9.416961</td>\n",
       "      <td>0.697558</td>\n",
       "      <td>...</td>\n",
       "      <td>96.678697</td>\n",
       "      <td>1.085942</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>106.953212</td>\n",
       "      <td>0.103623</td>\n",
       "      <td>0.750947</td>\n",
       "      <td>10.103915</td>\n",
       "      <td>287.063563</td>\n",
       "      <td>182.381630</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>0.185778</td>\n",
       "      <td>2.586515</td>\n",
       "      <td>13.922612</td>\n",
       "      <td>11.045361</td>\n",
       "      <td>14.866069</td>\n",
       "      <td>12.165525</td>\n",
       "      <td>15.842980</td>\n",
       "      <td>177.541667</td>\n",
       "      <td>7.855304</td>\n",
       "      <td>0.597379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980369</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.035664</td>\n",
       "      <td>1249.635335</td>\n",
       "      <td>0.482317</td>\n",
       "      <td>10.784729</td>\n",
       "      <td>8.190249</td>\n",
       "      <td>157.025183</td>\n",
       "      <td>127.207670</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>0.247844</td>\n",
       "      <td>2.471175</td>\n",
       "      <td>9.970706</td>\n",
       "      <td>7.280110</td>\n",
       "      <td>7.211103</td>\n",
       "      <td>7.615773</td>\n",
       "      <td>10.440307</td>\n",
       "      <td>70.041667</td>\n",
       "      <td>4.521458</td>\n",
       "      <td>0.708770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485198</td>\n",
       "      <td>0.065029</td>\n",
       "      <td>0.058473</td>\n",
       "      <td>932.906672</td>\n",
       "      <td>0.567195</td>\n",
       "      <td>13.052093</td>\n",
       "      <td>5.208441</td>\n",
       "      <td>112.331939</td>\n",
       "      <td>81.383582</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>0.273192</td>\n",
       "      <td>11.674262</td>\n",
       "      <td>42.732887</td>\n",
       "      <td>49.040799</td>\n",
       "      <td>50.219518</td>\n",
       "      <td>46.097722</td>\n",
       "      <td>51.048996</td>\n",
       "      <td>13760.916667</td>\n",
       "      <td>38.858918</td>\n",
       "      <td>0.635278</td>\n",
       "      <td>...</td>\n",
       "      <td>1720.046093</td>\n",
       "      <td>0.333574</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>6304.555601</td>\n",
       "      <td>0.066844</td>\n",
       "      <td>1.970785</td>\n",
       "      <td>39.406106</td>\n",
       "      <td>5153.821649</td>\n",
       "      <td>25205.225767</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_shape_Flatness  original_shape_LeastAxisLength  \\\n",
       "2646                 0.375133                        4.534490   \n",
       "2647                 0.687954                        8.589183   \n",
       "2648                 0.185778                        2.586515   \n",
       "2649                 0.247844                        2.471175   \n",
       "2650                 0.273192                       11.674262   \n",
       "\n",
       "      original_shape_MajorAxisLength  original_shape_Maximum2DDiameterColumn  \\\n",
       "2646                       12.087678                               12.806248   \n",
       "2647                       12.485120                               14.422205   \n",
       "2648                       13.922612                               11.045361   \n",
       "2649                        9.970706                                7.280110   \n",
       "2650                       42.732887                               49.040799   \n",
       "\n",
       "      original_shape_Maximum2DDiameterRow  \\\n",
       "2646                            11.401754   \n",
       "2647                            14.317821   \n",
       "2648                            14.866069   \n",
       "2649                             7.211103   \n",
       "2650                            50.219518   \n",
       "\n",
       "      original_shape_Maximum2DDiameterSlice  original_shape_Maximum3DDiameter  \\\n",
       "2646                              13.928388                         14.628739   \n",
       "2647                              12.649111                         15.165751   \n",
       "2648                              12.165525                         15.842980   \n",
       "2649                               7.615773                         10.440307   \n",
       "2650                              46.097722                         51.048996   \n",
       "\n",
       "      original_shape_MeshVolume  original_shape_MinorAxisLength  \\\n",
       "2646                 313.083333                        9.595771   \n",
       "2647                 605.541667                        9.416961   \n",
       "2648                 177.541667                        7.855304   \n",
       "2649                  70.041667                        4.521458   \n",
       "2650               13760.916667                       38.858918   \n",
       "\n",
       "      original_shape_Sphericity  ...  original_glszm_ZoneVariance  \\\n",
       "2646                   0.664923  ...                     5.572814   \n",
       "2647                   0.697558  ...                    96.678697   \n",
       "2648                   0.597379  ...                     0.980369   \n",
       "2649                   0.708770  ...                     0.485198   \n",
       "2650                   0.635278  ...                  1720.046093   \n",
       "\n",
       "      original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n",
       "2646                 0.127000                   0.026869   \n",
       "2647                 1.085942                   0.012166   \n",
       "2648                 0.095890                   0.035664   \n",
       "2649                 0.065029                   0.058473   \n",
       "2650                 0.333574                   0.000815   \n",
       "\n",
       "      original_ngtdm_Complexity  original_ngtdm_Contrast  \\\n",
       "2646                 692.801198                 0.218292   \n",
       "2647                 106.953212                 0.103623   \n",
       "2648                1249.635335                 0.482317   \n",
       "2649                 932.906672                 0.567195   \n",
       "2650                6304.555601                 0.066844   \n",
       "\n",
       "      original_ngtdm_Strength   Diameter  SurfaceArea        Volume  \\\n",
       "2646                 7.349337   9.827235   254.249082    140.178680   \n",
       "2647                 0.750947  10.103915   287.063563    182.381630   \n",
       "2648                10.784729   8.190249   157.025183    127.207670   \n",
       "2649                13.052093   5.208441   112.331939     81.383582   \n",
       "2650                 1.970785  39.406106  5153.821649  25205.225767   \n",
       "\n",
       "      Malignancy  \n",
       "2646         4.0  \n",
       "2647         4.0  \n",
       "2648         4.0  \n",
       "2649         2.0  \n",
       "2650         2.0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dataset=pd.read_csv(mainpath)\n",
    "main_dataset.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc0dbe3",
   "metadata": {},
   "source": [
    "## Spliting Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e310b83",
   "metadata": {},
   "source": [
    "We are firstly going to make the data division based on Pareto´s Law (80% training/20% testing) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121d8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collumn_name='Malignancy_round'\n",
    "#features_collumns=main_dataset.drop(collumn_name,axis=1)\n",
    "features_collumns=main_dataset.drop('Malignancy',axis=1)\n",
    "has_cancer_collumns=main_dataset['Malignancy']\n",
    "\n",
    "features_treino, features_teste, has_cancer_treino, has_cancer_teste=train_test_split(features_collumns,has_cancer_collumns, test_size=0.2)\n",
    "#has_cancer_collumns\n",
    "#features_collumns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda639b",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abb0fb",
   "metadata": {},
   "source": [
    "Although we say in the index that we have to build the Bootstrapped Dataset the sklearn random forest classifier has the ability to do that for us alowing us to skip a step<br>\n",
    "<br>\n",
    "In this chapter we´ll have some sub-chapters so that we can play around with the random Forest Classifier to try and get the best possible model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7a1df0",
   "metadata": {},
   "source": [
    "### Default Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570b76a5",
   "metadata": {},
   "source": [
    "#### DataFitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ef9789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier()\n",
    "RandomForest.fit(features_treino,has_cancer_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f14e64c",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdce928",
   "metadata": {},
   "source": [
    "##### Prediction Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1f2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_cancer_prediction=RandomForest.predict(features_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6bd6b",
   "metadata": {},
   "source": [
    "##### Accuracy Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89972a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5555555555555556 in a percentage of 100 = 55.55555555555556\n"
     ]
    }
   ],
   "source": [
    "#accuracy= explained_variance_score(has_cancer_teste, has_cancer_prediction)\n",
    "accuracy = accuracy_score(has_cancer_teste, has_cancer_prediction)\n",
    "print(f\"Accuracy = {accuracy} in a percentage of 100 = {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60572ec6",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb0781",
   "metadata": {},
   "source": [
    "Now let's see if by changing the parameters we can get a better solution<br>\n",
    "<br>\n",
    "With sklearn we have some comands that help us with this such as RandomizedSearchCV, but let´s first talk about the parameters we'll be messing with:<br>\n",
    "- n_estimators: Represents the amount of Decision Trees in our Forest, we'll try to change the value in increments of 20 to try and find an \"optimal\" value between [50,400]<br>\n",
    "- criterion: criterion in the trees we'll be testing gini vs entropy<br>\n",
    "- max_features: the number of features that each tree will have, according to some studies the best values should be around $\\sqrt{TotalFeatures}$ or log<sub>2</sub>(TotalFeatures)<br>\n",
    "- min_samples_split: that represents the minimum samples to split a node<br>\n",
    "- max_depth: in changing this value we can optimize our model and reduce the risk of overfitting\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6f02b",
   "metadata": {},
   "source": [
    "#### Stackable Improvements Assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50754539",
   "metadata": {},
   "source": [
    "Note that this is only one proposal of a potential model for this problem where we are going to make some assumptions in order to find if those a are true.\n",
    "<br>\n",
    "The first of those is that we'll make the superficial and perhaps stupid assumption that if a parameter improves the accuracy when adjusted by himself that, the improvement is going to stack with the improvement that we get from tuning other parameter by themselfs.<br>\n",
    "<br>\n",
    "By the end we'll see if this assumption holds or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c990f71",
   "metadata": {},
   "source": [
    "##### Finding the best Tree number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd900104",
   "metadata": {},
   "source": [
    "- For this we'll test the tree numbers in increments of 10 <br>\n",
    "- Our accuracy score for each number of trees will be given by an average of 5 tests <br>\n",
    "- After this we'll save the best value<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=50\n",
    "b=400\n",
    "values=[]\n",
    "treenumber=[]\n",
    "for i in range (a,b,10):\n",
    "    average_accuracy=0\n",
    "\n",
    "    for k in range (5):\n",
    "        RandomForesttree = RandomForestClassifier(n_estimators=i, n_jobs=(-1))\n",
    "        RandomForesttree.fit(features_treino,has_cancer_treino)\n",
    "        has_cancer_predictiontree=RandomForesttree.predict(features_teste)\n",
    "        accuracy = accuracy_score(has_cancer_teste, has_cancer_predictiontree)\n",
    "        average_accuracy+=accuracy\n",
    "    values.append(average_accuracy/5)\n",
    "    treenumber.append(i)\n",
    "\n",
    "pyplot.plot(treenumber,values )\n",
    "pyplot.xlabel('trees')\n",
    "pyplot.ylabel('accuracy') \n",
    "pyplot.title('Correlation between trees and Accuracy')\n",
    "pyplot.show() \n",
    "\n",
    "values=np.array(values)\n",
    "index=np.where(values==np.max(values))\n",
    "besttree=treenumber[index[0][0]]\n",
    "print(f\"Best tree value={besttree} accuracy = {np.max(values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d060ef0",
   "metadata": {},
   "source": [
    "##### Finding the best criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce681425",
   "metadata": {},
   "source": [
    "We'll test three criterion:<br>\n",
    "- Gini<br>\n",
    "- Entropy<br>\n",
    "- Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d16586",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gini=0\n",
    "accuracy_entropy=0\n",
    "accuracy_logloss=0\n",
    "for i in range (5):\n",
    "    RandomForestGini = RandomForestClassifier(criterion=\"gini\", n_jobs=(-1))\n",
    "    RandomForestGini.fit(features_treino,has_cancer_treino)\n",
    "    has_cancer_predictionGini=RandomForestGini.predict(features_teste)\n",
    "    accuracy_gini_iter = accuracy_score(has_cancer_teste, has_cancer_predictionGini)\n",
    "    accuracy_gini+=accuracy_gini_iter\n",
    "\n",
    "    RandomForestEntropy = RandomForestClassifier(criterion=\"entropy\", n_jobs=(-1))\n",
    "    RandomForestEntropy.fit(features_treino,has_cancer_treino)\n",
    "    has_cancer_predictionEntropy=RandomForestEntropy.predict(features_teste)\n",
    "    accuracy_entropy_iter = accuracy_score(has_cancer_teste, has_cancer_predictionEntropy)\n",
    "    accuracy_entropy+=accuracy_entropy_iter\n",
    "\n",
    "    RandomForestlogloss = RandomForestClassifier(criterion=\"log_loss\", n_jobs=(-1))\n",
    "    RandomForestlogloss.fit(features_treino,has_cancer_treino)\n",
    "    has_cancer_predictionlogloss=RandomForestlogloss.predict(features_teste)\n",
    "    accuracy_logloss_iter = accuracy_score(has_cancer_teste, has_cancer_predictionlogloss)\n",
    "    accuracy_logloss+=accuracy_logloss_iter\n",
    "\n",
    "accuracy_gini=accuracy_gini/5\n",
    "accuracy_entropy=accuracy_entropy/5\n",
    "accuracy_logloss=accuracy_logloss/5\n",
    "\n",
    "bestcriterionacc=(np.max([accuracy_entropy, accuracy_gini, accuracy_logloss]))\n",
    "if bestcriterionacc==accuracy_gini:\n",
    "    bestcriterionname='gini'\n",
    "if bestcriterionacc==accuracy_entropy:\n",
    "    bestcriterionname='entropy'\n",
    "if bestcriterionacc==accuracy_logloss:\n",
    "    bestcriterionname='log_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy Gini = {accuracy_gini} in a percentage of 100 = {accuracy_gini*100}\")\n",
    "print(f\"Accuracy Entropy = {accuracy_entropy} in a percentage of 100 = {accuracy_entropy*100}\")\n",
    "print(f\"Accuracy Log Loss = {accuracy_logloss} in a percentage of 100 = {accuracy_logloss*100}\")\n",
    "print(f\"Best criterion = {bestcriterionname} with an accuracy of = {bestcriterionacc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7f25ea",
   "metadata": {},
   "source": [
    "##### Finding the best minimum samples split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b20462",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower=2\n",
    "upper=40\n",
    "values=[]\n",
    "samplesnumber=[]\n",
    "for i in range (lower,upper):\n",
    "    average_accuracy=0\n",
    "\n",
    "    for k in range (5):\n",
    "        RandomForestSamples = RandomForestClassifier(min_samples_split=i, n_jobs=(-1))\n",
    "        RandomForestSamples.fit(features_treino,has_cancer_treino)\n",
    "        has_cancer_predictionsamples=RandomForestSamples.predict(features_teste)\n",
    "        accuracy = accuracy_score(has_cancer_teste, has_cancer_predictionsamples)\n",
    "        average_accuracy+=accuracy\n",
    "    values.append(average_accuracy/5)\n",
    "    samplesnumber.append(i)\n",
    "    \n",
    "pyplot.plot(samplesnumber,values )\n",
    "pyplot.xlabel('samples')\n",
    "pyplot.ylabel('accuracy') \n",
    "pyplot.title('Correlation between minimum samples and Accuracy')\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "values=np.array(values)\n",
    "index=np.where(values==np.max(values))\n",
    "bestsample=samplesnumber[index[0][0]]\n",
    "print(f\"Best Sample value={bestsample}, max accuracy={np.max(values)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5978c3ab",
   "metadata": {},
   "source": [
    "##### Finding the best Tree deepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower=2\n",
    "upper=20\n",
    "values=[]\n",
    "depthnumber=[]\n",
    "for i in range (lower,upper):\n",
    "    average_accuracy=0\n",
    "\n",
    "    for k in range (5):\n",
    "        RandomForestdepth = RandomForestClassifier(max_depth=i, n_jobs=(-1))\n",
    "        RandomForestdepth.fit(features_treino,has_cancer_treino)\n",
    "        has_cancer_predictiondepth=RandomForestdepth.predict(features_teste)\n",
    "        accuracy = accuracy_score(has_cancer_teste, has_cancer_predictiondepth)\n",
    "        average_accuracy+=accuracy\n",
    "    values.append(average_accuracy/5)\n",
    "    depthnumber.append(i)\n",
    "\n",
    "\n",
    "\n",
    "pyplot.plot(depthnumber,values )\n",
    "pyplot.xlabel('depth')\n",
    "pyplot.ylabel('accuracy') \n",
    "pyplot.title('Correlation tree depth and Accuracy')\n",
    "pyplot.show()\n",
    "\n",
    "values=np.array(values)\n",
    "index=np.where(values==np.max(values))\n",
    "bestdepthnumber=depthnumber[index[0][0]]\n",
    "print(f\"Best depth value={bestdepthnumber}, max accuracy={np.max(values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55cc7e",
   "metadata": {},
   "source": [
    "##### Finding the best Max Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9124a3",
   "metadata": {},
   "source": [
    "In this we have two options $\\sqrt{TotalFeatures}$ or log<sub>2</sub>(TotalFeatures), that have been shown by studies to be the best two value.<br> But these two values tend to be very similar unless TotalFeatures is a high number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173022b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sqr=0\n",
    "accuracy_log=0\n",
    "for i in range (5):\n",
    "    RandomForestsqr = RandomForestClassifier(max_features='sqrt', n_jobs=(-1))\n",
    "    RandomForestsqr.fit(features_treino,has_cancer_treino)\n",
    "    has_cancer_predictionsqr=RandomForestsqr.predict(features_teste)\n",
    "    accuracy_sqr_iter = accuracy_score(has_cancer_teste, has_cancer_predictionsqr)\n",
    "    accuracy_sqr+=accuracy_sqr_iter\n",
    "\n",
    "    RandomForestlog = RandomForestClassifier(max_features='log2', n_jobs=(-1))\n",
    "    RandomForestlog.fit(features_treino,has_cancer_treino)\n",
    "    has_cancer_predictionlog=RandomForestlog.predict(features_teste)\n",
    "    accuracy_log_iter = accuracy_score(has_cancer_teste, has_cancer_predictionlog)\n",
    "    accuracy_log+=accuracy_log_iter\n",
    "\n",
    "accuracy_sqr=accuracy_sqr/5\n",
    "accuracy_log=accuracy_log/5\n",
    "\n",
    "best_maxsamples_acc=(np.max([accuracy_sqr, accuracy_log,]))\n",
    "if best_maxsamples_acc==accuracy_sqr:\n",
    "    best_max_samples_name='sqrt'\n",
    "if best_maxsamples_acc==accuracy_log:\n",
    "    best_max_samples_name='log2'\n",
    "\n",
    "print(f\"Accuracy Sqr= {accuracy_sqr} in a percentage of 100 = {accuracy_sqr*100}\")\n",
    "print(f\"Accuracy Log= {accuracy_log} in a percentage of 100 = {accuracy_log*100}\")\n",
    "print(f\"Difference = {abs(accuracy_log-accuracy_sqr)}\")\n",
    "print(f\"Best Max Samples = {best_max_samples_name} with an accuracy of = {best_maxsamples_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c61422",
   "metadata": {},
   "source": [
    "##### Model with \"optimal stacking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0174da",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_optimal=0\n",
    "for i in range(5):\n",
    "    RandomForestoptimal = RandomForestClassifier(n_estimators=besttree, criterion=bestcriterionname, min_samples_split=bestsample, max_features=bestsample, max_depth=bestdepthnumber, n_jobs=(-1))\n",
    "    RandomForestoptimal.fit(features_treino,has_cancer_treino)\n",
    "    has_cancer_predictionoptimal=RandomForestoptimal.predict(features_teste)\n",
    "    accuracy_optimal_iter = accuracy_score(has_cancer_teste, has_cancer_predictionoptimal)\n",
    "    accuracy_optimal+=accuracy_optimal_iter\n",
    "accuracy_optimal=accuracy_optimal/5\n",
    "\n",
    "print (f\"Optimal stacking model accuracy = {accuracy_optimal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0731517",
   "metadata": {},
   "source": [
    "###### Confusion Matrix \"optimal stacking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(has_cancer_teste, has_cancer_predictionoptimal)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6d697",
   "metadata": {},
   "source": [
    "###### Tree from \"optimal stacking\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2661a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = RandomForestoptimal.estimators_[i]\n",
    "dot_data = export_graphviz(tree,\n",
    "                            feature_names=features_treino.columns,  \n",
    "                            filled=True,  \n",
    "                            max_depth=2, \n",
    "                            impurity=False, \n",
    "                            proportion=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c86eee",
   "metadata": {},
   "source": [
    "##### Proposal conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bde989",
   "metadata": {},
   "source": [
    "Since the accuracy of the model with the stacked optimal parameters is lower than the accuracy of the tuning of some individual parameters we can safelly say that stacking the best parameters isn't a good idea and the \"optimal\" value for a parameter can change depending on the value of other parameters.<br>\n",
    "<br>\n",
    "But we can also say that due to the \"optimal stacking\" model accuracy beeing higher than the default we can also assume that changing the parameters even if with a bad proposal it's better than leaving them with the default values<br>\n",
    "<br>\n",
    "We've also seen that due to the above test beeing done with only 8 features that it limits in various aways the model for exemple the difference between the square root of 8 and the log of base 2 of 8 is 0.2 and beeing that you can't choose 0.2 of a feature the trees had the same exact number of features in both of those tests making the difference 0 wich also doesn't allows us to know the effects of both.<br>\n",
    "<br>\n",
    "Also the low number of features renders usseles the efforts of increasing the amount of trees in the forest, because if it chooses let's say the square root of x, beeing x the total number of features that in this case is 8 there is only about 300 different ways to structure a tree with those 3 features picked at random per tree and of those 300 trees alot of them will be overfit, which explains why in none of the tests runned the best tree number was higher than 220."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512034ef",
   "metadata": {},
   "source": [
    "#### The computer is Smarter Assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c5407",
   "metadata": {},
   "source": [
    "Let's now give the computer ability to test diferent parameters at random to find the best parameters<br>\n",
    "<br>\n",
    "We won't need to create another forest because we already have the default one wich is the one we'll be using\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7754149a-6562-4a08-947f-e67cb4bf9322",
   "metadata": {},
   "source": [
    "##### Create the Dictionary for the range of values on the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf2fc6-4975-4ddf-9c4a-244317aa58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Range = {'n_estimators': randint(50,500), \n",
    "              'max_depth': randint(1,20), \n",
    "              'criterion': ['gini', 'entropy', 'log_loss'], \n",
    "              'min_samples_split': randint(2,50), \n",
    "              'max_features': ['sqrt','log2']\n",
    "              }\n",
    "\n",
    "print(Range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb57153",
   "metadata": {},
   "source": [
    "##### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomSearch = RandomizedSearchCV(RandomForest, param_distributions = Range, n_iter=40, n_jobs=(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443724f8",
   "metadata": {},
   "source": [
    "###### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc646c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomSearch.fit(features_treino, has_cancer_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fdf48",
   "metadata": {},
   "source": [
    "###### Best parameters found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a2b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Random_Search = RandomSearch.best_estimator_\n",
    "print('Best hyperparameters:',  RandomSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed0a777",
   "metadata": {},
   "source": [
    "###### Accuracy of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_cancer_prediction_BestRandomSearch = Best_Random_Search.predict(features_teste)\n",
    "accuracy_BestRandomSearch = accuracy_score(has_cancer_teste, has_cancer_prediction_BestRandomSearch)\n",
    "print(accuracy_BestRandomSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06aafd",
   "metadata": {},
   "source": [
    "###### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmrandom=confusion_matrix(has_cancer_teste, has_cancer_prediction_BestRandomSearch)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cmrandom).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ccde0",
   "metadata": {},
   "source": [
    "##### Assumption conclution and findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e1347b",
   "metadata": {},
   "source": [
    "Before the conclusion just a little find for our model:<br>\n",
    "In regards to time: Total_time ≈ Number_of_iterations * 0,561<br>\n",
    "<br>\n",
    "This method was in fact better than the previous model, but it still is no where perfect or good, 64% of accuracy although better is still far from good<br>\n",
    "I think that this model still suffers from the same problems as the other that beeing the lack of features that pylidc provides.<br>\n",
    "<br>\n",
    "Also We've found out that more itterations doesn't always correlate to a better outcome due to the randomness of it, you can find sometimes a better model with less iterations if you are just lucky enough.<br>\n",
    "<br>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
